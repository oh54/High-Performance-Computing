\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Computing Specifications}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table of the full machine specifications.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:spec}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Assignment}{2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Implementation of the sequential Jacobi iterative process}{2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Implementation of the sequential Gauss-Seidel iterative process}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The convergence of the Jacobi method and the Gauss-Seidel method with changing threshold.\relax }}{3}}
\newlabel{fig:itd}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Comparing convergence}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The convergence of the Jacobi method and the Gauss-Seidel method with changing matrix size.\relax }}{4}}
\newlabel{fig:itN}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Comparing performance}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The performance of the two sequential functions with changing domain size. The black dashed lines represent the cache sizes of the CPU.\relax }}{5}}
\newlabel{fig:seq_perf}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}OpenMP of the Jacobi Method}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Scaling of the first parallelized version.\relax }}{6}}
\newlabel{fig:omp_scale1}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Scaling of the second parallelized version of the whole computational while loop.\relax }}{7}}
\newlabel{fig:omp2_scale}{{5}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Speedup with varying matrix size}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Speed-up scaling of the third parallelized version, which includes parallel memory allocation.\relax }}{8}}
\newlabel{fig:omp3_scale}{{6}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Effiency plot of the three parallel versions.\relax }}{8}}
\newlabel{fig:omp_eff}{{7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The speedup of the Jacobi iteration with the best parallellization method, \texttt  {omp3}, with different matrix sizes.\relax }}{9}}
\newlabel{fig:speedup_N}{{8}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Speedup with different compiler option}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Comparison with Mandelbrot program}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The speedup of the two the parallelization of the mandelbrot computation with the default scheduling, with a chunk size of 10 compared to the speedup of the Jacobi iteration.\relax }}{10}}
\newlabel{fig:mandelbrot}{{9}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {3}OpenMP Gauss-Seidel}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{11}}
